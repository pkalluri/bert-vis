{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = '../../../bucket/wikipedia/1000docs_19513contexts_30maxtokens/'\n",
    "contexts_filename = 'contexts.pickle'\n",
    "acts_filename = 'activations.npz'\n",
    "\n",
    "layers = ['arr_0','arr_3','arr_6', 'arr_9', 'arr_12']  # which layers to visualize\n",
    "# layers = ['arr_0']  # good for debugging\n",
    "reduction, dim = 'PCA', 2\n",
    "view_vis_as_html = False  # If True, running the vis will also generate an interactive html file and open it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# LOAD\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "project_path = os.path.abspath('../../..')\n",
    "sys.path.insert(0, project_path)\n",
    "from src.utils import acts_util\n",
    "# TAG\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from src.utils import context_util\n",
    "# VIS\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "if view_vis_as_html:\n",
    "    output_file('visualize-wiki.html')\n",
    "from bokeh.models import Div\n",
    "from bokeh.layouts import gridplot\n",
    "from src.utils import vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contexts and acts\n",
    "with open(os.path.join(os.path.abspath(data_dir), contexts_filename), 'rb') as f:\n",
    "    contexts_list = pickle.load(f)\n",
    "acts_npz = np.load(os.path.join(data_dir, acts_filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_acts = {layer: acts_npz[layer] for layer in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reductions\n",
    "reduced_acts = {layer:acts_util.reduce_acts(acts, reduction, dim) for (layer,acts) in layer_to_acts.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Properties of contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "contexts = pd.DataFrame()\n",
    "# basics\n",
    "contexts['tokens'] = [toks for toks, position in contexts_list]\n",
    "contexts['position'] = [position for toks, position in contexts_list]\n",
    "contexts['context html'] = contexts['tokens'].combine(contexts['position'], context_util.context_html)\n",
    "contexts['context length'] = contexts['tokens'].apply(len)\n",
    "contexts['abbreviated context'] = contexts['tokens'].combine(contexts['position'], context_util.abbreviated_context)\n",
    "contexts['abbreviated context html'] = contexts['tokens'].combine(contexts['position'], context_util.abbreviated_context_html)\n",
    "contexts['token'] = contexts['tokens'].combine(contexts['position'], lambda toks,position: toks[position])\n",
    "contexts['doc'] = contexts['tokens'].apply(lambda toks: ' '.join(toks))\n",
    "# activations\n",
    "for layer in layers:\n",
    "    contexts[f'{layer} x'] = layer_to_acts[layer][:,0]\n",
    "    contexts[f'{layer} y'] = layer_to_acts[layer][:,1] \n",
    "for layer in layers:\n",
    "    contexts[f'{layer} {reduction} x'] = reduced_acts[layer][:,0]\n",
    "    contexts[f'{layer} {reduction} y'] = reduced_acts[layer][:,1]    \n",
    "\n",
    "# subspace activations\n",
    "subspaces_to_inspect = {} \n",
    "toks_to_inspect = ['[CLS]', '[SEP]', '.', 'the', ',','born',]\n",
    "for tok in toks_to_inspect:\n",
    "    subspaces_to_inspect[tok] = (contexts[contexts['token']==tok]).index\n",
    "for (name, context_idxs) in subspaces_to_inspect.items():\n",
    "    print(f'{name} ({len(context_idxs)} contexts)')\n",
    "    for layer in layers:\n",
    "        subspace_acts = layer_to_acts[layer][context_idxs]\n",
    "        subspace_reduced_acts = acts_util.reduce_acts(subspace_acts, reduction, dim)\n",
    "        contexts.loc[context_idxs, f'{layer} \"{name}\" {reduction} x'] = subspace_reduced_acts[:,0] \n",
    "        contexts.loc[context_idxs, f'{layer} \"{name}\" {reduction} y'] = subspace_reduced_acts[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properties\n",
    "def reverse_position(toks, position): return len(toks)-1-position\n",
    "contexts['position from end'] = contexts['tokens'].combine(contexts['position'], reverse_position)\n",
    "def POS_tag(toks, position): return nltk.pos_tag(toks)[position][1]\n",
    "contexts['POS'] = contexts['tokens'].combine(contexts['position'], POS_tag)\n",
    "contexts['CLS'] = contexts['token']=='[CLS]'\n",
    "contexts['SEP'] = contexts['token']=='[SEP]'\n",
    "contexts['.'] = contexts['token']=='.'\n",
    "contexts['token length'] = contexts['token'].apply(len)\n",
    "contexts['1st'] = contexts['position']==0\n",
    "contexts['2nd'] = contexts['position']==1\n",
    "contexts['nth'] = contexts['position']+1==contexts['context length']\n",
    "contexts['(n-1)th'] = contexts['position']+2==contexts['context length']\n",
    "contexts['(n-2)th'] = contexts['position']+1+2==contexts['context length']\n",
    "def is_capitalized(tok): return bool(re.match('[A-Z]', tok))\n",
    "contexts['capitalized'] = contexts['token'].apply(is_capitalized)\n",
    "def is_partial(tok): return tok.startswith('##')\n",
    "contexts['partial'] = contexts['token'].apply(is_partial)\n",
    "def has_number(tok): return bool(re.search('[0-9]', tok))\n",
    "contexts['has number'] = contexts['token'].apply(has_number)\n",
    "def is_month(tok): return tok in ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n",
    "contexts['is month'] = contexts['token'].apply(is_month)\n",
    "def is_year(tok): return bool(re.match('^[12][0-9]{3}$', tok))\n",
    "contexts['is year'] = contexts['token'].apply(is_year)\n",
    "def before_partial(toks, pos): return (pos+2 < len(toks)) and is_partial(toks[pos+2])\n",
    "contexts['before partial'] = contexts['tokens'].combine(contexts['position'], before_partial)\n",
    "def before_double_capitals(toks, pos): \n",
    "    return (pos+2 < len(toks)) and is_capitalized(toks[pos+1]) and is_capitalized(toks[pos+2])\n",
    "contexts['before double capitals'] = contexts['tokens'].combine(contexts['position'], before_double_capitals)\n",
    "def not_before_sep(toks, pos): return (pos+1 < len(toks)) and toks[pos+1]!='[SEP]'\n",
    "contexts['not_before_sep'] = contexts['tokens'].combine(contexts['position'], not_before_sep)\n",
    "def after_year(toks, pos): return (pos-1 >= 0) and is_year(toks[pos-1])\n",
    "contexts['after_year'] = contexts['tokens'].combine(contexts['position'], after_year)\n",
    "def is_initial(tok): return bool(re.match('^[A-Z]$', tok))\n",
    "def after_initial(toks, pos): return (pos-1 >= 0) and is_initial(toks[pos-1])\n",
    "contexts['after_initial'] = contexts['tokens'].combine(contexts['position'], after_initial)\n",
    "def is_number(tok): return bool(re.match('^[0-9]+$', tok))\n",
    "def number_seperator(toks, pos): return (pos-1 >= 0) and is_number(toks[pos-1]) and pos+1 < len(toks) and is_number(toks[pos+1])\n",
    "contexts['number_seperator'] = contexts['tokens'].combine(contexts['position'], number_seperator)\n",
    "def after_partial(toks, pos): return (pos-1 >= 0) and is_partial(toks[pos-1])\n",
    "contexts['after_partial'] = contexts['tokens'].combine(contexts['position'], after_partial)\n",
    "def after_capitalized(toks, pos): return (pos-1 >= 0) and is_capitalized(toks[pos-1])\n",
    "contexts['after_capitalized'] = contexts['tokens'].combine(contexts['position'], after_capitalized)\n",
    "def is_CC(tok): return tok in ['and', 'but']\n",
    "def before_CC(toks, pos): return (pos+1 < len(toks)) and is_CC(toks[pos+1])\n",
    "contexts['before_CC'] = contexts['tokens'].combine(contexts['position'], before_CC)\n",
    "def is_date(tok): return bool(re.match('^([1-9]|[12][0-9]|3[01])$', tok))\n",
    "def date_separator(toks, pos): \n",
    "    return  (pos-1 >= 0 and\n",
    "             pos+1 < len(toks) and \n",
    "             toks[pos] == ',' and\n",
    "             is_date(toks[pos-1]) and \n",
    "             is_year(toks[pos+1])\n",
    "            )\n",
    "contexts['date_separator'] = contexts['tokens'].combine(contexts['position'], date_separator)\n",
    "def before_capitalized(toks, pos): return (pos+1 < len(toks)) and is_capitalized(toks[pos+1])\n",
    "contexts['before_capitalized'] = contexts['tokens'].combine(contexts['position'], before_capitalized)\n",
    "def _between_caps(toks, pos): \n",
    "    return (\n",
    "        (pos-1 >= 0) and \n",
    "        (is_capitalized(toks[pos-1]) or is_partial(toks[pos-1])) and \n",
    "        (pos+1 < len(toks) and is_capitalized(toks[pos+1]))\n",
    "    )\n",
    "contexts['_between_caps'] = contexts['tokens'].combine(contexts['position'], _between_caps)\n",
    "def between_caps(toks, pos): return (pos-1 >= 0) and is_capitalized(toks[pos-1]) and pos+1 < len(toks) and is_capitalized(toks[pos+1])\n",
    "contexts['between_caps'] = contexts['tokens'].combine(contexts['position'], between_caps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fresh visualization\n",
    "layer_labels = [Div(text=layer, align=('center', 'center')) for layer in layers]\n",
    "visualizations = [[None]+layer_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global space\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, []))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('CLS','.','SEP')))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('1st','2nd','(n-2)th','(n-1)th','nth')))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('position',)))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('token length',)))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('capitalized','partial')))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, reduction, ('has number','is month')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local subspaces\n",
    "visualizations.append(vis_util.visualize_columns(contexts, layers, f'\"[CLS]\" {reduction}', []))\n",
    "\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\"[SEP]\" {reduction}', []))\n",
    "visualizations.append(vis_util.visualize_columns(contexts, layers, f'\"[SEP]\" {reduction}', ('position',)))\n",
    "\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\".\" {reduction}', []))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\".\" {reduction}', ('position',)))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\".\" {reduction}', (\n",
    "#     'not_before_sep','after_year',\n",
    "# )))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\".\" {reduction}', (\n",
    "#     'not_before_sep','after_capitalized','after_partial','after_year','after_initial', 'number_seperator' \n",
    "# )))\n",
    "\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\",\" {reduction}', []))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\",\" {reduction}', ('position',)))\n",
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\",\" {reduction}', (\n",
    "#     'after_capitalized','after_partial','after_year','before_CC', 'number_seperator', 'date_separator', \n",
    "#     '_between_caps'\n",
    "# )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualizations.append(vis_util.visualize_columns(contexts, layers, f'\"born\" {reduction}', []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show(gridplot(zip(*visualizations)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-vis",
   "language": "python",
   "name": "bert-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
