{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand a context through its clusters, its neighbors, and custom possible neighbors\n",
    "Examine, at each layer, the given context's KNNs - both KNNs in the corpus and the KNNs out of its own masked variants - as well as any custom contexts you're curious about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "# from sklearn.neighbors import NearestNeighbors  # for now, switching to FasterNearestNeighbors\n",
    "from IPython.core.display import display, HTML\n",
    "import time\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils.acts_util import spherize, fit_components\n",
    "from utils.bert_util import get_masked_variants\n",
    "from utils.context_util import context_html, context_str\n",
    "from utils.html_util import highlighter, fix_size, font_size, style\n",
    "from utils import vis_util, html_util\n",
    "from utils import references as refs\n",
    "from utils.SimpleGPT2 import SimpleGPT2\n",
    "from utils.FastNearestNeighbors import FastNearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGPT2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sphere = True  # Spherize the activations? This is equivalent to switching from standard Euclidean distance to cosine distance.\n",
    "n_layers = 37  # Only visualizes n layers, selected evenly from the available layers. \n",
    "              # E.g. if n_layers=5 and 12 layers are avaiilable, will visualize layers 0,3,6,9,1 (n_layers = 2 is good for debugging)\n",
    "vis_color = True \n",
    "reduction, dim = 'NMF', 10  # Reduction with which to color the doc\n",
    "vis_size = False  # If visualizing color, can also visualize size\n",
    "\n",
    "vis_masked_KNNs = False\n",
    "pruning = False  \n",
    "# pruning is only checked if visualizing masked KNNs.     \n",
    "# if pruning is true, in the masked neighbors vis, first the closest 1-token-long mask is presented, \n",
    "# then jumps to the closest 2-token-long mask, etc - forming a kind of slow pruning to capture the essence of the context.\n",
    "vis_corpus_KNNs = False\n",
    "corpus_dir = '/atlas/u/pkalluri/bert-vis/big-data/wiki-large'  # only checked if visualizing corpus KNNs\n",
    "vis_custom_contexts = False\n",
    "together = True  # Instead of visualizing all masked KNNs, then all corpus KNNs, etc, do you want to visit them all together, sorted by distance?\n",
    "save_to_html = False\n",
    "html_path = '../../../building-blocks.html'  # only checked if saving to html\n",
    "\n",
    "doc_txt = '''\n",
    "Alice was beginning to get very tired of sitting by her sister on the\n",
    "bank, and of having nothing to do: once or twice she had peeped into the\n",
    "book her sister was reading, but it had no pictures or conversations in\n",
    "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
    "conversation?'\n",
    "\n",
    "So she was considering in her own mind (as well as she could, for the\n",
    "hot day made her feel very sleepy and stupid), whether the pleasure\n",
    "of making a daisy-chain would be worth the trouble of getting up and\n",
    "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
    "close by her.\n",
    "\n",
    "There was nothing so VERY remarkable in that; nor did Alice think it so\n",
    "VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
    "Oh dear! I shall be late!' (when she thought it over afterwards, it\n",
    "occurred to her that she ought to have wondered at this, but at the time\n",
    "it all seemed quite natural); but when the Rabbit actually TOOK A WATCH\n",
    "OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on,\n",
    "Alice started to her feet, for it flashed across her mind that she had\n",
    "never before seen a rabbit with either a waistcoat-pocket, or a watch\n",
    "to take out of it, and burning with curiosity, she ran across the field\n",
    "after it, and fortunately was just in time to see it pop down a large\n",
    "rabbit-hole under the hedge.\n",
    "'''\n",
    "selected_tok = 'woman'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get tokens and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, doc_acts = model.get_toks_and_acts(doc_txt)\n",
    "layers = list(doc_acts)\n",
    "n = int((len(layers)-1)/(n_layers-1)) # will visualize every nth layer\n",
    "layers = layers[::n]\n",
    "if sphere: doc_acts = {layer: spherize(doc_acts[layer]) for layer in layers}\n",
    "\n",
    "print('\\nDocument:')\n",
    "print(' '.join(doc))\n",
    "print(f'\\nLayers: {\", \".join(layers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Reduce sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if vis_color:\n",
    "    doc_components = {}\n",
    "    doc_reduced_acts = {}\n",
    "    for layer in layers:\n",
    "        _components, _reduced_acts = fit_components(doc_acts[layer], reduction, dim)\n",
    "        doc_components[layer] = _components\n",
    "        doc_reduced_acts[layer] = _reduced_acts\n",
    "    if vis_size:\n",
    "        doc_acts_sizes = {layer: np.linalg.norm(doc_acts[layer], axis=1) for layer in layers}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_masked_KNNs or vis_corpus_KNNs: selected_tok_idx = doc.index(selected_tok)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get corpus neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_corpus_KNNs:\n",
    "    # io\n",
    "    corpus_dir = os.path.abspath(corpus_dir)\n",
    "    corpus_contexts = pickle.load(open(os.path.join(corpus_dir, refs.contexts_fn),'rb'))\n",
    "    corpus_acts = np.load(os.path.join(corpus_dir, refs.acts_fn))\n",
    "    n_neighbors = 20\n",
    "\n",
    "    # get KNNs\n",
    "    corpus_neighbors = {}\n",
    "    for layer in layers:\n",
    "        print(f'Layer {layer}')\n",
    "        _acts = spherize(corpus_acts[layer]) if sphere else corpus_acts[layer]\n",
    "        print('Fitting nearest neighbors model.')\n",
    "        knn_model = FastNearestNeighbors().fit(_acts)\n",
    "        del _acts\n",
    "        print('Finding neighbors.')\n",
    "        _doc_acts = doc_acts[layer]\n",
    "        neighs_dists, neighs_ids = knn_model.kneighbors([_doc_acts[selected_tok_idx]], n_neighbors=n_neighbors, return_distance=True)\n",
    "        del knn_model\n",
    "        neighs = [(neigh_id, corpus_contexts[neigh_id], neigh_dist) for neigh_id, neigh_dist in zip(neighs_ids[0], neighs_dists[0])]  # a neighbor is an id, the corresponding context, and the distance away\n",
    "        corpus_neighbors[layer] = neighs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Get masked neighbors - does this apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_masked_KNNs:\n",
    "    mask_lengths = range(max(len(doc)-3, 1),len(doc)-2)  # a parameter used for what mask_lengths to consider. currently hard-coded.\n",
    "    print('Getting variants.')\n",
    "    variants = get_masked_variants(doc, mask_lengths)\n",
    "    print('Getting activations.')\n",
    "    variants_contexts, variants_acts = model.get_contexts_and_acts(variants, tokenized=True)\n",
    "    n_neighbors = 20\n",
    "\n",
    "    masked_neighbors = {}\n",
    "    for layer in layers:\n",
    "        print(f'Layer {layer}')\n",
    "        _acts = spherize(variants_acts[layer]) if sphere else variants_acts[layer]\n",
    "        print('Fitting nearest neighbors model.')\n",
    "        knn_model = FastNearestNeighbors().fit(_acts)\n",
    "        print('Finding neighbors')\n",
    "        _doc_acts = doc_acts[layer]\n",
    "        neighs_dists, neighs_ids = knn_model.kneighbors([_doc_acts[selected_tok_idx]], n_neighbors=n_neighbors, return_distance=True)\n",
    "        neighs = [(variants_contexts[neigh_id], neigh_dist) for neigh_id, neigh_dist in zip(neighs_ids[0], neighs_dists[0])]  # a neighbor is a context, and the distance away\n",
    "        masked_neighbors[layer] = neighs\n",
    "        del knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Check similarity of custom sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_custom_contexts:\n",
    "    custom_contexts_unprocessed = [\n",
    "        ('A Chinese woman walked in.', 'Chinese'),\n",
    "        ]\n",
    "    custom_neighbors = {layer: [] for layer in layers}\n",
    "    for custom_txt, custom_tok in custom_contexts_unprocessed:\n",
    "        custom_doc, custom_doc_acts = model.get_toks_and_acts(custom_txt)\n",
    "        custom_pos = custom_doc.index(custom_tok)\n",
    "        custom_context = (custom_doc, custom_pos)\n",
    "        for layer in layers:\n",
    "            _act = doc_acts[layer][selected_tok_idx]\n",
    "            _custom_act = custom_doc_acts[layer][custom_pos]\n",
    "            if sphere: \n",
    "                _act = spherize([_act])[0]\n",
    "                _custom_act = spherize([_custom_act])[0]\n",
    "            dist = np.linalg.norm(_custom_act - _act)\n",
    "            custom_neighbors[layer].append((custom_context, dist))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VISUALIZE\n",
    "\n",
    "override_params = False  # useful for quick iteration on visualization\n",
    "if override_params:\n",
    "    vis_color = False\n",
    "    vis_size = False\n",
    "    vis_masked_KNNs = False\n",
    "    vis_corpus_KNNs = True\n",
    "    vis_custom_contexts = False\n",
    "    together = True\n",
    "    pruning=True  \n",
    "    save_to_html = False\n",
    "# other vis params\n",
    "max_font_size = 10\n",
    "# params if visualizing neighbors\n",
    "if vis_corpus_KNNs or vis_masked_KNNs or vis_custom_contexts:\n",
    "    n_neighbors_to_vis = 50\n",
    "    token_styler = lambda t: t\n",
    "    # token_styler = lambda t: style(font_size(fix_size(t),7), 'line-height:0px;')  # another pretty styling option\n",
    "\n",
    "# setup\n",
    "bluer = highlighter('lightblue')\n",
    "greener = highlighter('limegreen')\n",
    "greyer = highlighter('grey')\n",
    "masker = highlighter('black')\n",
    "if save_to_html: html_doc = ''\n",
    "if vis_masked_KNNs or vis_corpus_KNNs or vis_custom_contexts: selected_tok_html = context_html(doc, selected_tok_idx)\n",
    "\n",
    "# start visualizing\n",
    "# vis legend\n",
    "if vis_color:\n",
    "    pure_rgbs = vis_util.channels_to_rgbs(np.eye(dim))\n",
    "    html = ''\n",
    "    for i, rgb in enumerate(pure_rgbs):\n",
    "        html += html_util.style(f' {i} ', css=f'background-color: {html_util.rgb_to_color(*rgb)}')\n",
    "    print('Legend')\n",
    "    display(HTML(html))\n",
    "    if save_to_html: html_doc += html + '<br>'\n",
    "    print() \n",
    "    rgbs = {layer:vis_util.channels_to_rgbs(doc_reduced_acts[layer]) for layer in layers}  # prepare coloring\n",
    "\n",
    "corpus_neighs_so_far = []  \n",
    "for layer in layers:\n",
    "    html = f'Layer {layer}'\n",
    "    display(HTML(html))\n",
    "    if save_to_html: html_doc += html\n",
    "    \n",
    "    # vis sample\n",
    "    if vis_size:\n",
    "        _sizes = doc_acts_sizes[layer]\n",
    "        _sizes = (_sizes - np.min(_sizes)) / (np.max(_sizes) - np.min(_sizes))    \n",
    "    if vis_color:\n",
    "        _rgbs = rgbs[layer]\n",
    "        color_html = ''\n",
    "        for pos, tok in enumerate(doc):\n",
    "            if vis_size:\n",
    "                css = f'background-color: {html_util.rgb_to_color(*_rgbs[pos])}; font-size: {_sizes[pos]*max_font_size}pt;'\n",
    "            else:\n",
    "                css = f'background-color: {html_util.rgb_to_color(*_rgbs[pos])}; font-size: {max_font_size}pt;'\n",
    "            color_html += html_util.style(f' {tok} ', css=css)\n",
    "        display(HTML(color_html))\n",
    "        if save_to_html: html_doc += color_html + '<br>'\n",
    "    \n",
    "    # vis knns\n",
    "    if vis_masked_KNNs or vis_corpus_KNNs or vis_custom_contexts:\n",
    "        # Show the doc\n",
    "        display(HTML(selected_tok_html))\n",
    "        if save_to_html: html_doc += selected_tok_html + '<br>'\n",
    "        \n",
    "        if together:\n",
    "            neighbors = []\n",
    "            if vis_masked_KNNs:\n",
    "                neighbors.extend([(context, dist, 'masked') for context, dist in masked_neighbors[layer]])\n",
    "            if vis_corpus_KNNs:\n",
    "                neighbors.extend([(context, dist, 'corpus') for context_id, context, dist in corpus_neighbors[layer]])\n",
    "            if vis_custom_contexts:\n",
    "                neighbors.extend([(context, dist, 'custom') for context, dist in custom_neighbors[layer]])\n",
    "            neighbors.sort(key=lambda t: t[1])  # sort all by dist\n",
    "            \n",
    "            for neigh_context, neigh_dist, neigh_source in neighbors[:n_neighbors_to_vis]:\n",
    "                html = f'({neigh_dist:.3f}) '\n",
    "                if neigh_source == 'masked':\n",
    "                    html += context_html(*neigh_context, masker=masker, token_styler=token_styler)\n",
    "                elif neigh_source == 'corpus':\n",
    "                    marker = bluer if not neigh_context in corpus_neighs_so_far else greyer\n",
    "                    html += context_html(*neigh_context, marker=marker, masker=masker, token_styler=token_styler)\n",
    "                    corpus_neighs_so_far.append(neigh_context)\n",
    "                elif neigh_source == 'custom':\n",
    "                    html += context_html(*neigh_context, marker=greener, masker=masker, token_styler=token_styler)\n",
    "                display(HTML(html))\n",
    "                if save_to_html: html_doc += html + '<br>'\n",
    "        else:\n",
    "            if vis_masked_KNNs:\n",
    "                _masked_neighbors = masked_neighbors[layer]\n",
    "                if pruning:\n",
    "                    for mask_len_to_search in range(len(doc)-2):\n",
    "                        for neigh_context, neigh_dist in _masked_neighbors:\n",
    "                            neigh_toks, neigh_pos = neigh_context\n",
    "                            mask_len = len([tok for tok in neigh_toks if tok == '[MASK]'])\n",
    "                            if mask_len == mask_len_to_search:\n",
    "                                html = token_styler(f'({neigh_dist:.3f}) ') +  context_html(*neigh_context, token_styler=token_styler)\n",
    "                                display(HTML(html))\n",
    "                                if save_to_html: html_doc += html + '<br>'\n",
    "                                break\n",
    "                else:\n",
    "                    for neigh_context, neigh_dist in _masked_neighbors[:n_neighbors_to_vis]:\n",
    "                        html = token_styler(f'({neigh_dist:.3f}) ') + context_html(*neigh_context, token_styler=lambda t: token_styler(fix_size(t)))\n",
    "                        display(HTML(html))\n",
    "                        if save_to_html: html_doc += html + '<br>'\n",
    "            if vis_corpus_KNNs:\n",
    "                _corpus_neighs = corpus_neighbors[layer][:n_neighbors_to_vis]\n",
    "                for neigh_id, neigh_context, neigh_dist in _corpus_neighs:\n",
    "                    marker = bluer if not neigh_context in corpus_neighs_so_far else greyer\n",
    "                    html = token_styler(f'({neigh_dist:.3f})') + context_html(*neigh_context, marker=marker, token_styler=token_styler)\n",
    "                    display(HTML(html))\n",
    "                    if save_to_html: html_doc += html + '<br>'\n",
    "                    corpus_neighs_so_far.append(neigh_context)\n",
    "            if vis_custom_contexts:\n",
    "                _custom_neighbors = custom_neighbors[layer]\n",
    "                for context, dist in _custom_neighbors:\n",
    "                    marker = greener\n",
    "                    html = token_styler(f'({dist:.3f})') + context_html(*context, marker=marker, token_styler=token_styler)\n",
    "                    display(HTML(html))\n",
    "                    if save_to_html: html_doc += html + '<br>'\n",
    "    print('.')\n",
    "    print('.')\n",
    "    print('.')\n",
    "\n",
    "if save_to_html: open(html_path, 'w').write(html_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
