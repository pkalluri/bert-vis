{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand a context through its neighbors\n",
    "Examine, at each layer, the given context's KNNs in the corpus and the context's KNNs out of its masked variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "import warnings\n",
    "from typing import List\n",
    "import collections\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../..'))\n",
    "from src.utils import acts_util, vis_util, html_util, context_util, bert_util\n",
    "from src.utils.context_util import context_html\n",
    "from src.utils.html_util import highlighter, fix_size, font_size, style\n",
    "from src import references as refs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_corpus_KNNs = True\n",
    "vis_masked_KNNs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tokens and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set sample directory\n",
    "dir_path = os.path.abspath('../../../data/sentences/art/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc and acts\n",
    "doc = pickle.load(open(os.path.join(dir_path, refs.toks_fn), 'rb'))\n",
    "doc_acts = np.load(os.path.join(dir_path, refs.acts_fn))\n",
    "layers = doc_acts.files[:2] # change to fewer layers if you want\n",
    "\n",
    "print('\\nDocument:')\n",
    "print(' '.join(doc))\n",
    "print(f'\\nLayers: {\", \".join(layers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_of_interest = list(range(1,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_corpus_KNNs:\n",
    "    # GET K NEAREST NEIGHBORS FROM DATASET\n",
    "    # params\n",
    "    corpus_dir = '/Users/pkalluri/projects/clarity/bert-vis/big-data/wiki-large/standard'\n",
    "    knn_path = os.path.join(corpus_dir, refs.knn_models_fn)\n",
    "    n_neighbors = 20\n",
    "\n",
    "    # get KNNs\n",
    "    corpus_neighborhoods = {}\n",
    "    corpus_contexts = pickle.load(open(os.path.join(corpus_dir, refs.contexts_fn),'rb'))\n",
    "    with open(knn_path, 'rb') as f:\n",
    "        for layer in layers:\n",
    "            print(f'Layer {layer}')\n",
    "\n",
    "            print('Loading nearest neighbors model.')\n",
    "            knn_model = pickle.load(f)\n",
    "\n",
    "            print('Finding neighbors')\n",
    "            # a concise neighborhood is a single tuple of (neighbors' dists to the neighborhood's true token, neighbors' idxs)\n",
    "            concise_neighborhoods = zip(*knn_model.kneighbors(doc_acts[layer][toks_of_interest], n_neighbors=n_neighbors, return_distance=True))\n",
    "            # We want a more intuitive and useful representation:\n",
    "            # a neighborhood contains a list of neighbors; a neighbor is a tuple of (context, its dist to the true token)    \n",
    "            neighborhoods = []  \n",
    "            for concise_neighborhood in concise_neighborhoods:\n",
    "                neighborhood = [(corpus_contexts[neigh_idx], neigh_dist) for (neigh_dist, neigh_idx) in zip(*concise_neighborhood)]\n",
    "                neighborhoods.append(neighborhood)\n",
    "            corpus_neighborhoods[layer] = neighborhoods\n",
    "            del knn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_masked_KNNs:\n",
    "    # params\n",
    "    mask_lengths = [1,2,3,4,5,6,7]\n",
    "    # GET MASKED VARIANTS OF SAMPLE\n",
    "    variants = [doc] + bert_util.get_masked_variants(doc, mask_lengths)\n",
    "    variants_contexts, variants_acts = bert_util.get_contexts_and_acts(variants, tokenized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_masked_KNNs:\n",
    "    # GET KNNs FROM MASKED VARIANTS\n",
    "    # params\n",
    "    n_neighbors = 50\n",
    "\n",
    "    # get KNNs\n",
    "    masked_neighborhoods = {}\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "        print('Fit nearest neighbors model.')\n",
    "        knn_model = NearestNeighbors(n_neighbors=n_neighbors).fit(variants_acts[layer])\n",
    "\n",
    "        print('Finding neighbors')\n",
    "        # a concise neighborhood is a single tuple of (neighbors' dists to the neighborhood's true token, neighbors' idxs)\n",
    "        concise_neighborhoods = zip(*knn_model.kneighbors(variants_acts[layer][toks_of_interest], n_neighbors=n_neighbors, return_distance=True))\n",
    "        # We want a more intuitive and useful representation:\n",
    "        # a neighborhood contains a list of neighbors; a neighbor is a tuple of (context, its dist to the true token)    \n",
    "        neighborhoods = []  \n",
    "        for concise_neighborhood in concise_neighborhoods:\n",
    "            neighborhood = [(variants_contexts[neigh_idx], neigh_dist) for (neigh_dist, neigh_idx) in zip(*concise_neighborhood)]\n",
    "            neighborhoods.append(neighborhood)\n",
    "        masked_neighborhoods[layer] = neighborhoods\n",
    "        del knn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# random.seed(0)\n",
    "# vis_rand_KNNs = True\n",
    "# if vis_rand_KNNs:\n",
    "#     all_toks = [tok for (toks, pos) in corpus_contexts for tok in toks]\n",
    "#     rand_toks = random.sample(all_toks, 20)\n",
    "#     variants = itertools.combinations(all_toks, 1)\n",
    "# #     counter=collections.Counter(all_toks)\n",
    "#     variants_contexts, variants_acts = bert_util.get_docs_contexts_and_acts(variants, tokenized=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vis KNNs in corpus and KNNs in masked variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZE\n",
    "# params\n",
    "n_neighbors_to_vis = 20\n",
    "vis_corpus_KNNs = True\n",
    "vis_masked_KNNs = True\n",
    "together = False\n",
    "token_styler = lambda t: style(font_size(fix_size(t),7), 'line-height:0px;')\n",
    "\n",
    "# vis\n",
    "tok_of_interest = 'The'\n",
    "tok_of_interest_idx = doc.index(tok_of_interest)\n",
    "neigh_idx = toks_of_interest.index(tok_of_interest_idx)  # it should be one of the toks of interested we searched for\n",
    "display(HTML(context_html(doc, toks_of_interest[tok_of_interest_idx])))\n",
    "bluer = highlighter('lightblue')\n",
    "for layer in layers:\n",
    "    print(f'Layer {layer}')\n",
    "    if together:\n",
    "        neighbors = []\n",
    "        if vis_masked_KNNs:\n",
    "            neighbors.extend([(context, dist, 'masked') for context, dist in masked_neighborhoods[layer][neigh_idx]][1:n_neighbors_to_vis])\n",
    "        if vis_corpus_KNNs:\n",
    "            neighbors.extend([(context, dist, 'corpus') for context, dist in corpus_neighborhoods[layer][neigh_idx]][1:n_neighbors_to_vis])\n",
    "        neighbors.sort(key=lambda t: t[1])\n",
    "        for neigh_context, neigh_dist, neigh_dataset in neighbors[:n_neighbors_to_vis]:\n",
    "            html = f'({neigh_dist:.2f}) '\n",
    "            if neigh_dataset == 'masked':\n",
    "                html += context_html(*neigh_context, masker=masker, token_styler=token_styler)\n",
    "            elif neigh_dataset == 'corpus':\n",
    "                html += context_html(*neigh_context, marker=bluer, masker=masker, token_styler=token_styler)\n",
    "            display(HTML(html))\n",
    "    else:\n",
    "        if vis_masked_KNNs:\n",
    "            neighbors = masked_neighborhoods[layer][neigh_idx][:n_neighbors_to_vis]\n",
    "            for neigh_context, neigh_dist in neighbors:  # masked neighbors\n",
    "                html = token_styler(f'({neigh_dist:.2f}) ') + context_html(*neigh_context, token_styler=lambda t: token_styler(fix_size(t)))\n",
    "                display(HTML(html))\n",
    "        if vis_corpus_KNNs:\n",
    "            neighbors = corpus_neighborhoods[layer][tok_of_interest_idx][:n_neighbors_to_vis]\n",
    "            for neigh_context, neigh_dist in neighbors:  # corpus neighbors\n",
    "                html = token_styler(f'({neigh_dist:.2f}) ') + context_html(*neigh_context, marker=bluer, token_styler=token_styler)\n",
    "                display(HTML(html))\n",
    "    print('.')\n",
    "    print('.')\n",
    "    print('.')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vis mask pruning (remove one token at a time to visualize the essence of the context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PRUNING\n",
    "# params\n",
    "masker = highlighter('black')\n",
    "# token_styler = lambda t: html_util.font_size(t, 7)\n",
    "token_styler = lambda t: style(font_size(t,10), 'line-height:0px;')\n",
    "\n",
    "# vis one token's neighbors\n",
    "tok_of_interest = 'The'\n",
    "tok_of_interest_idx = doc.index(tok_of_interest)\n",
    "neigh_idx = toks_of_interest.index(tok_of_interest_idx)\n",
    "display(HTML(context_html(doc, tok_of_interest_idx)))\n",
    "for layer in layers:\n",
    "    print(f'Layer {layer}')\n",
    "    bluer = highlighter('lightblue')\n",
    "    neighbors = []\n",
    "    neighbors.extend([(neigh_context, neigh_dist, 'masked') for neigh_context, neigh_dist in masked_neighborhoods[layer][neigh_idx]][1:])\n",
    "#     neighbors.extend([(context, dist, 'corpus') for context, dist in corpus_neighborhoods[layer][neigh_idx]][1:])\n",
    "#     neighbors.sort(key=lambda neigh: len([tok for tok in neigh[0] if tok=='[MASK]']))\n",
    "    for mask_len_to_find in range(len(doc)-2):\n",
    "        for neigh_context, neigh_dist, neigh_dataset in neighbors:\n",
    "            neigh_toks, neigh_pos = neigh_context\n",
    "            mask_len = len([tok for tok in neigh_toks if tok == '[MASK]'])\n",
    "            if mask_len == mask_len_to_find:\n",
    "                html = ''\n",
    "                if neigh_dataset == 'masked':\n",
    "                    html += token_styler(f'({neigh_dist:.2f}) ') +  context_html(*neigh_context, masker=masker, token_styler=token_styler)\n",
    "                elif neigh_dataset == 'corpus':\n",
    "                    html += token_styler(f'({neigh_dist:.2f}) ') + context_html(*neigh_context, marker=bluer, masker=masker, token_styler=token_styler)\n",
    "                display(HTML(html))\n",
    "                break\n",
    "    print('.')\n",
    "    print('.')\n",
    "    print('.')  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose\n",
    "layer = layers[1]\n",
    "new_text = 'The [MASK] floor exhibits classical art.'\n",
    "new_tok_of_interest = 'The'\n",
    "\n",
    "# vis\n",
    "new_doc, new_acts = bert_util.get_toks_and_acts(new_text)\n",
    "new_poos = new_doc.index(new_tok_of_interest)\n",
    "current_act = doc_acts[layer][tok_of_interest_idx]\n",
    "new_act = new_acts[layer][new_poos]\n",
    "display(HTML(f'Layer {layer}'))\n",
    "dist = np.linalg.norm(current_act - new_act)\n",
    "bluer = highlighter('lightblue')\n",
    "token_styler = lambda t: font_size(t,10)\n",
    "html = token_styler(f'({dist:.2f}) ')\n",
    "html += context_html(new_doc, new_poos, marker=bluer, token_styler=token_styler)\n",
    "display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-vis",
   "language": "python",
   "name": "bert-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
