{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "data_dir = '../../bucket/wikipedia/1000docs_19513contexts_30maxtokens/'\n",
    "contexts_filename = 'contexts.pickle'\n",
    "acts_filename = 'activations.npz'\n",
    "n_nearest_neighbors = 10\n",
    "KNN_models_filename = f'KNN_models_K={n_nearest_neighbors}.pickle'\n",
    "# layers = ['arr_0','arr_3','arr_6', 'arr_9', 'arr_12']  # which layers to visualize\n",
    "layers = [f'arr_{i}' for i in range(13)]\n",
    "# layers = ['arr_0']  # good for debugging\n",
    "reductions = [('KernelPCA',2)]\n",
    "view_vis_as_html = False  # If True, running the vis will also generate an interactive html file and open it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "# LOAD\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "project_path = os.path.abspath('../..')\n",
    "sys.path.insert(0, project_path)\n",
    "from src.utils import acts_util\n",
    "# TAG\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from src.utils import context_util\n",
    "# VIS\n",
    "from bokeh.plotting import figure, show, output_file\n",
    "from bokeh.io import output_notebook\n",
    "output_notebook()\n",
    "if view_vis_as_html:\n",
    "    output_file('visualize-movement.html')\n",
    "from bokeh.models import Label, LabelSet, Div, ColumnDataSource, Legend, LegendItem\n",
    "from bokeh.models import HoverTool, CustomJS, PanTool, BoxZoomTool, WheelZoomTool, ResetTool, TapTool, OpenURL\n",
    "from bokeh.models.glyphs import Circle\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh import events\n",
    "from bokeh.palettes import Inferno, Category10, Category20, Category20c, Pastel1, Pastel2, Bokeh, Plasma\n",
    "from src.utils import vis_util, html_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading contexts and acts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load contexts and layer_to_acts\n",
    "with open(os.path.join(os.path.abspath(data_dir), contexts_filename), 'rb') as f:\n",
    "    contexts = pickle.load(f)\n",
    "acts_npz = np.load(os.path.join(data_dir, acts_filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_acts = {layer: acts_npz[layer] for layer in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reductions\n",
    "# reduced_acts = acts.copy()\n",
    "# for layer in layers:\n",
    "#     print(layer)\n",
    "#     for reduction, dim in reductions:\n",
    "#         curr_acts = reduced_acts[layer]\n",
    "#         reduced_acts[layer] = acts_util.reduce_activations(curr_acts, reduction, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Dimensionality reduce doc and KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_number = 101\n",
    "doc_ids = context_util.get_doc_ids(contexts, doc_number)\n",
    "doc, _ = contexts[doc_ids[0]]\n",
    "print(context_util.doc_str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nearest_neighbors = 10\n",
    "KNN_models_filename = f'KNN_models_K={n_nearest_neighbors}.pickle'\n",
    "\n",
    "# K Nearest Neighbor models\n",
    "with open(os.path.join(os.path.abspath(data_dir), KNN_models_filename), 'rb') as f:\n",
    "    layer_to_KNN_model = pickle.load(f)\n",
    "layer_to_neighbors = {}  # for each tok in document, map it to its nearest neighbors' ids\n",
    "for layer in layers:\n",
    "    acts = layer_to_acts[layer]\n",
    "    KNN_model = layer_to_KNN_model[layer]\n",
    "    neighbors_distances, neighbors_ids = KNN_model.kneighbors(acts[doc_ids])\n",
    "    layer_to_neighbors[layer] = neighbors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fresh vis\n",
    "columns = []\n",
    "layer_name_column = [None] + [Div(text=layer, align=('center', 'center')) for layer in layers]\n",
    "columns.append(layer_name_column)\n",
    "\n",
    "# optionally focus on subset of doc\n",
    "start_pos, end_pos = 2,-2\n",
    "phrase = doc[start_pos:end_pos]\n",
    "phrase_ids = doc_ids[start_pos:end_pos]\n",
    "# set vis params\n",
    "palette = Category20[20]\n",
    "# create a column of plots\n",
    "plot_column = []\n",
    "plot_column.append(Div(text=' '.join([f'{reduction}{dim}' for reduction, dim in reductions]), align=('center', 'center'))) # column header\n",
    "for layer in layers:\n",
    "    # fit this layer's dimensionality reduction model\n",
    "    phrase_neighbors = layer_to_neighbors[layer][start_pos:end_pos]\n",
    "    ids_to_fit = phrase_ids + flatten(phrase_neighbors)  # multiple options here\n",
    "    acts = layer_to_acts[layer]\n",
    "    acts_to_fit = acts[ids_to_fit]  # init\n",
    "    fit_reducers = []\n",
    "    for reduction, dim in reductions:\n",
    "        fit_reducer, acts_to_fit = acts_util.fit_reducer(acts_to_fit, reduction, dim)\n",
    "        fit_reducers.append(fit_reducer)\n",
    "    \n",
    "    # reduce and prep the document's points\n",
    "    phrase_contexts = [contexts[context_id] for context_id in phrase_ids]\n",
    "    phrase_reduced_acts = acts[phrase_ids]  # init\n",
    "    for reducer in fit_reducers:\n",
    "        phrase_reduced_acts = reducer.transform(phrase_reduced_acts)\n",
    "    phrase_points = {\n",
    "        'x': phrase_reduced_acts[:,0],\n",
    "        'y': phrase_reduced_acts[:,1],\n",
    "        'color': [palette[tok_idx] for tok_idx in range(len(phrase))],\n",
    "        'line color': ['black'] * len(phrase),\n",
    "        'line width': [1] * len(phrase),\n",
    "        'label': [[f'[{pos}]'] for doc, pos in phrase_contexts],\n",
    "        'hover label': [context_util.context_str(*context, marker=html_util.highlighter(color='yellow')) for context in phrase_contexts]\n",
    "        }\n",
    "\n",
    "    # reduce and prep the neighbors\n",
    "    processed_neighbors = []\n",
    "    neighbor_points = {'x':[], 'y':[], 'color':[], 'legend label':[], 'label':[], 'hover label':[]}\n",
    "    for tok_idx in range(len(phrase)):\n",
    "        tok_pos = tok_idx + start_pos  # position relative to entire doc\n",
    "        tok_neighbors = phrase_neighbors[tok_idx][1:]  # skip zeroeth neighbor; that's the token itself\n",
    "        tok_neighbors_contexts = [contexts[neighbor] for neighbor in tok_neighbors]\n",
    "        tok_neighbors_reduced_acts = acts[tok_neighbors]  # init\n",
    "        for reducer in fit_reducers:\n",
    "            tok_neighbors_reduced_acts = reducer.transform(tok_neighbors_reduced_acts)\n",
    "            \n",
    "        # visualize different kinds of neighbors differently\n",
    "        for neighbor_idx, neighbor in enumerate(tok_neighbors):\n",
    "            if neighbor in phrase_ids:  # update existing phrase point\n",
    "                phrase_point_idx = phrase_ids.index(neighbor)\n",
    "                phrase_points['label'][phrase_point_idx] += f'{tok_pos}'\n",
    "                phrase_points['line color'][phrase_point_idx] = 'aqua'\n",
    "                phrase_points['line width'][phrase_point_idx] = 3\n",
    "            elif neighbor in processed_neighbors:  # update existing neighbor point\n",
    "                neighbor_point_idx = processed_neighbors.index(neighbor)\n",
    "                neighbor_points['label'][neighbor_point_idx] += f'{tok_pos}'\n",
    "                neighbor_points['color'][neighbor_point_idx] = 'aqua'\n",
    "            else:  # new neighbor\n",
    "                neighbor_context = contexts[neighbor]\n",
    "                neighbor_reduced_acts = tok_neighbors_reduced_acts[neighbor_idx]\n",
    "                neighbor_points['x'].append(neighbor_reduced_acts[0])\n",
    "                neighbor_points['y'].append(neighbor_reduced_acts[1])\n",
    "                neighbor_points['color'].append(palette[tok_idx])\n",
    "                neighbor_points['legend label'].append([f'[{tok_pos}] {doc[tok_pos]}'])\n",
    "                neighbor_points['label'].append([f'{tok_pos}'])\n",
    "                neighbor_points['hover label'].append(\n",
    "                    context_util.context_str(*neighbor_context, marker=html_util.highlighter(color='lightgrey')))\n",
    "                processed_neighbors.append(neighbor)    \n",
    "    neighbor_points['label'] = [label if len(label)>1 else '' for label in neighbor_points['label']]\n",
    "    \n",
    "    # plot \n",
    "    phrase_points_source = ColumnDataSource(phrase_points)\n",
    "    neighbor_points_source = ColumnDataSource(neighbor_points)\n",
    "    p = vis_util.empty_plot(width=400, height=250, darkmode=False)\n",
    "    p.add_layout(Legend(), 'right')\n",
    "    p.circle(x='x', y='y', color='color', size=10, legend_group='legend label', source=neighbor_points_source)\n",
    "    p.add_layout(LabelSet(x='x', y='y', text='label', x_offset=2, y_offset=2, text_font_size='10pt', source=neighbor_points_source))\n",
    "    p.triangle(x='x', y='y', color='color', line_color='line color', size=15, line_width='line width', source=phrase_points_source)\n",
    "    p.add_layout(LabelSet(x='x', y='y', text='label', x_offset=2, y_offset=2, text_font_size='10pt', source=phrase_points_source))\n",
    "    zoom_tool = WheelZoomTool()\n",
    "    p.tools = [PanTool(), zoom_tool, BoxZoomTool(), ResetTool(), HoverTool(tooltips=vis_util.custom_bokeh_tooltip('hover label'))]\n",
    "    p.toolbar.active_scroll = zoom_tool\n",
    "    plot_column.append(p)\n",
    "columns.append(plot_column)\n",
    "show(gridplot(zip(*columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use KNN as dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One doc\n",
    "doc_number = 101\n",
    "doc_ids = context_util.get_doc_ids(contexts, doc_number)\n",
    "doc, _ = contexts[doc_ids[0]]\n",
    "doc, doc_ids = doc, doc_ids\n",
    "print(context_util.doc_str(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nearest_neighbors = 10\n",
    "KNN_models_filename = f'KNN_models_K={n_nearest_neighbors}.pickle'\n",
    "with open(os.path.join(os.path.abspath(data_dir), KNN_models_filename), 'rb') as f:\n",
    "    layer_to_KNN_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer_to_KNN = {}\n",
    "# for layer in layers:\n",
    "#     acts = layer_to_acts[layer]\n",
    "#     KNN_model = layer_to_KNN_model[layer]\n",
    "#     neighbors_distances, neighbors_ids = KNN_model.kneighbors(acts)\n",
    "#     layer_to_KNN[layer] = neighbors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_to_doc_KNN = {}\n",
    "for layer in layers:\n",
    "    acts = layer_to_acts[layer]\n",
    "    KNN_model = layer_to_KNN_model[layer]\n",
    "    neighbors_distances, neighbors_ids = KNN_model.kneighbors(acts[doc_ids])\n",
    "    layer_to_doc_KNN[layer] = neighbors_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reductions = [('PCA',2)]\n",
    "layer_to_doc_reduced_KNN = layer_to_doc_KNN.copy()\n",
    "# do reductions\n",
    "for layer in layers:\n",
    "    print(layer)\n",
    "    for reduction, dim in reductions:\n",
    "        curr_vals = layer_to_doc_reduced_KNN[layer]\n",
    "        layer_to_doc_reduced_KNN[layer] = acts_util.reduce_activations(curr_vals, reduction, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = []\n",
    "columns.append([None] + [Div(text=layer, align=('center', 'center')) for layer in layers])   # layer names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "palette = Inferno[256][::20]\n",
    "green_highlighter = lambda tok: html_util.highlight_html(tok, color='limegreen')\n",
    "plot_column = [Div(text=' '.join([f'{reduction}{dim}' for reduction, dim in reductions]), align=('center', 'center'))]\n",
    "for layer in layers:\n",
    "    p = vis_util.empty_plot(dim=300, darkmode=True)\n",
    "    points = layer_to_doc_reduced_KNN[layer]  \n",
    "    doc_contexts = [contexts[context_idx] for context_idx in doc_ids]\n",
    "    doc_source = ColumnDataSource(\n",
    "        {\n",
    "            'x': points[:,0],\n",
    "            'y': points[:,1],\n",
    "            'color': palette[:len(reduced_acts)],\n",
    "            'label': [pos for doc, pos in doc_contexts],\n",
    "            'hover label': [context_util.context_str(*context, marker=green_highlighter) for context in doc_contexts]\n",
    "        }\n",
    "    )\n",
    "    p.circle(x='x', y='y', color='color', size=5, source=doc_source)\n",
    "    p.add_layout(LabelSet(x='x', y='y', text='label', x_offset=2, y_offset=2, source=doc_source, render_mode='canvas', text_font_size='10pt'))\n",
    "    \n",
    "    # add lines connecting document tokens in order\n",
    "    for point_start_idx in range(len(points)):\n",
    "        endpoints = points[point_start_idx: point_start_idx+2]\n",
    "        xs, ys = zip(*endpoints)\n",
    "        p.line(x=xs, y=ys, color=palette[point_start_idx], line_width=4)\n",
    "    p.tools = [PanTool(), WheelZoomTool(), BoxZoomTool(), ResetTool(), HoverTool(tooltips=custom_tooltip('{hover label}'))]\n",
    "    plot_column.append(p)\n",
    "columns.append(plot_column)\n",
    "show(gridplot(zip(*columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = list(Inferno[256][::20])\n",
    "p = vis_util.empty_plot(darkmode=True, dim=200)\n",
    "layer_to_doc_travel = {}\n",
    "\n",
    "for tok_idx, tok in enumerate(doc):\n",
    "    travelled_distance = []\n",
    "    prev_layer = layers[0]\n",
    "    for layer_idx, layer in enumerate(layers):\n",
    "        direction = layer_to_doc_KNN[prev_layer][tok_idx] - layer_to_doc_KNN[layer][tok_idx]\n",
    "        travelled_distance.append(np.linalg.norm(direction))\n",
    "#         prev_layer = layer\n",
    "    p.line(x=range(len(travelled_distance)), y=travelled_distance, color=palette[tok_idx])\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = list(Inferno[256][::20])\n",
    "p = vis_util.empty_plot(darkmode=True, dim=200)\n",
    "layer_to_doc_travel = {}\n",
    "\n",
    "for tok_idx, tok in enumerate(doc):\n",
    "    travelled_distance = []\n",
    "    prev_layer = layers[0]\n",
    "    for layer_idx, layer in enumerate(layers):\n",
    "        direction = layer_to_doc_KNN[prev_layer][tok_idx] - layer_to_doc_KNN[layer][tok_idx]\n",
    "        travelled_distance.append(np.linalg.norm(direction))\n",
    "        prev_layer = layer\n",
    "    p.line(x=range(len(travelled_distance)), y=travelled_distance, color=palette[tok_idx])\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-vis",
   "language": "python",
   "name": "bert-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
