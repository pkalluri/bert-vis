{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See a sample through BERT's eyes (clusters, size, and KNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "from IPython.core.display import display, HTML\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import glob\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../..'))\n",
    "from utils import acts_util, vis_util, html_util, context_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Load tokens and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set sample directory\n",
    "dir_path = os.path.abspath('../../../data/short-sentence/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Checking files are valid\n",
    "name = dir_path.split('/')[-1] \n",
    "tokens_path = os.path.join(dir_path, \"tokens.pickle\")\n",
    "acts_path = os.path.join(dir_path, f\"activations.npz\")\n",
    "\n",
    "print(f'Directory: \\'{name}\\'')\n",
    "print(f'Path to tokens: \\'{tokens_path}\\'')\n",
    "assert os.path.exists(tokens_path), f'File does not exist: {os.path.abspath(tokens_path)}'\n",
    "print(f'Path to reduced activations: \\'{acts_path}\\'')\n",
    "assert os.path.exists(acts_path), f'File does not exist: {os.path.abspath(acts_path)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open(tokens_path, 'rb') as f:\n",
    "    tokens = pickle.load(f)\n",
    "doc = ' '.join(tokens)\n",
    "layer_to_acts = np.load(acts_path)\n",
    "layers = layer_to_acts.files\n",
    "\n",
    "print('\\nDocument:')\n",
    "print(doc)\n",
    "print(f'\\nLayers: {\", \".join(layers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualize activations, reduced by NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# REDUCE ACTS\n",
    "reduction, dim = 'NMF', 3\n",
    "visualize_size = True\n",
    "max_font_size = 10\n",
    "\n",
    "layer_to_components = {}\n",
    "layer_to_reduced_acts = {}\n",
    "for layer, acts in layer_to_acts.items():\n",
    "    components, reduced_acts = acts_util.fit_components(acts, reduction, dim)\n",
    "    layer_to_components[layer] = components\n",
    "    layer_to_reduced_acts[layer] = reduced_acts\n",
    "if visualize_size:\n",
    "    layer_to_acts_sizes = {layer: np.linalg.norm(acts, axis=1) for layer, acts in layer_to_acts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# GET ACTS NEAREST NEIGHBORS\n",
    "visualize_NNs = True\n",
    "corpus_dir = '/Users/pkalluri/projects/clarity/bert-vis/bucket/wiki-large/wiki-split/'\n",
    "contexts_fn = 'contexts.pickle'\n",
    "acts_fn = 'activations.npz'\n",
    "knn_fn = 'KNN_models_K5.pickle'\n",
    "n_neighbors = 5\n",
    "\n",
    "print(f'Path to corpus: {corpus_dir}')\n",
    "assert os.path.exists(os.path.join(corpus_dir)), f'File does not exist: {corpus_dir}'\n",
    "assert os.path.exists(os.path.join(corpus_dir, knn_fn)), f'File does not exist: {corpus_dir}'\n",
    "assert os.path.exists(os.path.join(corpus_dir, contexts_fn)), f'Contexts does not exist.'\n",
    "assert os.path.exists(os.path.join(corpus_dir, acts_fn)), f'Contexts does not exist.'\n",
    "\n",
    "layer_to_comp_neighborhoods = {}\n",
    "layer_to_target_neighborhoods = {}\n",
    "if visualize_NNs:\n",
    "    corpus_contexts = pickle.load(open(os.path.abspath(os.path.join(corpus_dir, contexts_fn)),'rb'))\n",
    "    with open(os.path.join(corpus_dir, knn_fn), 'rb') as f:\n",
    "        for layer in layers:\n",
    "            print(layer)\n",
    "\n",
    "            print('Loading nearest neighbors model.')\n",
    "            model = pickle.load(f)\n",
    "\n",
    "            print('Finding neighbors')\n",
    "            components = layer_to_components[layer]\n",
    "            neighborhoods = model.kneighbors(components, n_neighbors=3, return_distance=False) # indices\n",
    "            neighborhoods = [[corpus_contexts[idx] for idx in neighborhood] for neighborhood in neighborhoods] # contexts\n",
    "            layer_to_comp_neighborhoods[layer] = neighborhoods\n",
    "\n",
    "            neighborhoods = model.kneighbors([acts[0]], n_neighbors=3, return_distance=False) # indices\n",
    "            neighborhoods = [[corpus_contexts[idx] for idx in neighborhood] for neighborhood in neighborhoods] # contexts\n",
    "            layer_to_target_neighborhoods[layer] = neighborhoods\n",
    "            \n",
    "            del model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# VISUALIZE\n",
    "\n",
    "# legend\n",
    "pure_rgbs = vis_util.channels_to_rgbs(np.eye(dim))\n",
    "html = ''\n",
    "for i, rgb in enumerate(pure_rgbs):\n",
    "    css = f'background-color: {html_util.rgb_to_color(*rgb)}'\n",
    "    html += html_util.style(f' {i} ', css=css)\n",
    "print('Legend')\n",
    "display(HTML(html))\n",
    "\n",
    "# vis\n",
    "layer_to_rgbs = {layer:vis_util.channels_to_rgbs(reduced_acts) for layer,reduced_acts in layer_to_reduced_acts.items()}\n",
    "for layer in layers:\n",
    "    rgbs = layer_to_rgbs[layer]\n",
    "    if visualize_size:\n",
    "        sizes = layer_to_acts_sizes[layer]\n",
    "        normalized_sizes = (sizes - np.min(sizes)) / (np.max(sizes) - np.min(sizes))\n",
    "    print(layer)\n",
    "    # vis sample\n",
    "    html = ''\n",
    "    for tok_idx, tok in enumerate(tokens):\n",
    "        if visualize_size:\n",
    "            css = f'background-color: {html_util.rgb_to_color(*rgbs[tok_idx])}; font-size: {normalized_sizes[tok_idx]*max_font_size}pt;'\n",
    "        else:\n",
    "            css = f'background-color: {html_util.rgb_to_color(*rgbs[tok_idx])}; font-size: {max_font_size}pt;'\n",
    "        html += html_util.style(f' {tok} ', css=css)\n",
    "    display(HTML(html))\n",
    "    \n",
    "    # vis neighbors\n",
    "    neighborhoods = layer_to_comp_neighborhoods[layer]\n",
    "    for pure_rgb, neighborhood in zip(pure_rgbs, neighborhoods):\n",
    "        color = html_util.rgb_to_color(*pure_rgb)\n",
    "        for context in neighborhood:\n",
    "            html = context_util.context_html(*context, highlighter=html_util.highlighter(color=color))\n",
    "            display(HTML(html))\n",
    "    neighborhoods = layer_to_target_neighborhoods[layer]\n",
    "    for i, neighborhood in enumerate(neighborhoods):\n",
    "        print(f'Target {i+1}')\n",
    "        for context in neighborhood:\n",
    "            html = context_util.context_html(*context)\n",
    "            display(HTML(html))\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bert-vis",
   "language": "python",
   "name": "bert-vis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
