{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand a context through its clusters, its neighbors, and custom possible neighbors\n",
    "Examine, at each layer, the given context's KNNs - both KNNs in the corpus and the KNNs out of its own masked variants - as well as any custom contexts you're curious about."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pickle\n",
    "import glob\n",
    "import random\n",
    "from typing import List\n",
    "import collections\n",
    "import itertools\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../../..'))\n",
    "from src.utils import acts_util, vis_util, html_util, context_util, bert_util\n",
    "from src.utils.context_util import context_html\n",
    "from src.utils.html_util import highlighter, fix_size, font_size, style\n",
    "from src.utils import references as refs\n",
    "from src.utils.SimpleBert import SimpleBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert = SimpleBert()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spherize = True\n",
    "vis_color = True\n",
    "reduction, dim = 'NMF', 3\n",
    "vis_size = True\n",
    "\n",
    "vis_masked_KNNs = True\n",
    "pruning = False\n",
    "vis_corpus_KNNs = True\n",
    "vis_custom_contexts = True\n",
    "together = True\n",
    "save_to_html = False\n",
    "\n",
    "doc_txt = \"Later that day, he caught her eye.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get tokens and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc, doc_acts = bert.get_toks_and_acts(doc_txt)\n",
    "layers = [layer for layer in doc_acts][::3]\n",
    "# layers = layers[:2] # for debugging\n",
    "if spherize: doc_acts = {layer: acts_util.spherize(doc_acts[layer]) for layer in layers}\n",
    "\n",
    "print('\\nDocument:')\n",
    "print(' '.join(doc))\n",
    "print(f'\\nLayers: {\", \".join(layers)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reduce sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_color:\n",
    "    # reduce\n",
    "    doc_components = {}\n",
    "    doc_reduced_acts = {}\n",
    "    for layer in layers:\n",
    "        _components, _reduced_acts = acts_util.fit_components(doc_acts[layer], reduction, dim)\n",
    "        doc_components[layer] = _components\n",
    "        doc_reduced_acts[layer] = _reduced_acts\n",
    "    if vis_size:\n",
    "        doc_acts_sizes = {layer: np.linalg.norm(doc_acts[layer], axis=1) for layer in layers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toks_of_interest = range(len(doc))  # todo: consider switching this to only one token of interest, since that's a common use case that simplifies all below code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get corpus neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_corpus_KNNs:\n",
    "    \n",
    "    # GET K NEAREST NEIGHBORS FROM DATASET\n",
    "    # params\n",
    "    corpus_dir = '/atlas/u/pkalluri/bert-vis/big-data/wiki-large'\n",
    "    subdir = 'sphere' if spherize else 'standard'  # todo: put these hardcodes in refs\n",
    "    knn_path = os.path.join(corpus_dir, subdir, refs.knn_models_fn)\n",
    "    n_neighbors = 20\n",
    "\n",
    "    # get KNNs\n",
    "    corpus_neighborhoods = {}\n",
    "    corpus_contexts = pickle.load(open(os.path.join(corpus_dir, subdir, refs.contexts_fn),'rb'))\n",
    "    with open(knn_path, 'rb') as f:\n",
    "        for layer in layers:\n",
    "            print(f'Layer {layer}')\n",
    "\n",
    "            print('Loading nearest neighbors model.')\n",
    "            knn_model = pickle.load(f)\n",
    "\n",
    "            print('Finding neighbors')\n",
    "            _doc_acts = doc_acts[layer]\n",
    "            # a concise neighborhood is a single tuple of (neighbors' dists to the neighborhood's true token, neighbors' ids)\n",
    "            concise_neighborhoods = zip(*knn_model.kneighbors(_doc_acts[toks_of_interest], n_neighbors=n_neighbors, return_distance=True))\n",
    "            # We want a more intuitive and useful representation:\n",
    "            # a neighborhood contains a list of neighbors; a neighbor is a tuple of (neigh_id, context, its dist to the true token)  \n",
    "            neighborhoods = [] \n",
    "            for concise_neighborhood in concise_neighborhoods:\n",
    "                neighborhood = [(neigh_id, corpus_contexts[neigh_id], neigh_dist) for (neigh_dist, neigh_id) in zip(*concise_neighborhood)]\n",
    "                neighborhoods.append(neighborhood)\n",
    "            corpus_neighborhoods[layer] = neighborhoods\n",
    "            del knn_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Get masked neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_masked_KNNs:\n",
    "    # params\n",
    "    mask_lengths = range(max(len(doc)-5, 1),len(doc)-2)\n",
    "    # GET MASKED VARIANTS OF SAMPLE\n",
    "    print('Getting variants.')\n",
    "    variants = [doc] + bert_util.get_masked_variants(doc, mask_lengths)\n",
    "    print('Getting activations.')\n",
    "    variants_contexts, variants_acts = bert.get_contexts_and_acts(variants, tokenized=True)\n",
    "    if spherize: variants_acts = {layer: acts_util.spherize(variants_acts[layer]) for layer in layers}\n",
    "    \n",
    "    # GET KNNs FROM MASKED VARIANTS\n",
    "    # params\n",
    "    n_neighbors = 50\n",
    "\n",
    "    # get KNNs\n",
    "    masked_neighborhoods = {}\n",
    "    for layer in layers:\n",
    "        print(layer)\n",
    "\n",
    "        print('Fitting nearest neighbors model.')\n",
    "        knn_model = NearestNeighbors(n_neighbors=n_neighbors).fit(variants_acts[layer])\n",
    "\n",
    "        print('Finding neighbors')\n",
    "        _variants_acts = variants_acts[layer]\n",
    "        # a concise neighborhood is a single tuple of (neighbors' dists to the neighborhood's true token, neighbors' idxs)\n",
    "        concise_neighborhoods = zip(*knn_model.kneighbors(_variants_acts[toks_of_interest], n_neighbors=n_neighbors, return_distance=True))\n",
    "        # We want a more intuitive and useful representation:\n",
    "        # a neighborhood contains a list of neighbors; a neighbor is a tuple of (context, its dist to the true token)    \n",
    "        neighborhoods = []  \n",
    "        for concise_neighborhood in concise_neighborhoods:\n",
    "            neighborhood = [(variants_contexts[neigh_idx], neigh_dist) for (neigh_dist, neigh_idx) in zip(*concise_neighborhood)]\n",
    "            neighborhoods.append(neighborhood)\n",
    "        masked_neighborhoods[layer] = neighborhoods\n",
    "        del knn_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check similarity of custom sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_of_interest = 'caught'\n",
    "tok_of_interest_idx = doc.index(tok_of_interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if vis_custom_contexts:\n",
    "    custom_contexts_untokenized = [('He caught it.', 'caught'),\n",
    "                               ('He caught her eye.', 'caught'),\n",
    "                               ('The rabbit caught the fox\\'s eye.', 'caught'),\n",
    "                               ('The rabbit caught the fox\\'s attention.', 'caught'),\n",
    "                               ('0 1 2 3 4 caught 6 7 8.', 'caught'),\n",
    "                               ('He [MASK] it.', '[MASK]'),\n",
    "                               ('He [MASK] her eye.', '[MASK]'),\n",
    "                               ('The rabbit [MASK] the fox\\'s eye.', '[MASK]'),\n",
    "                               ('The rabbit [MASK] the fox\\'s attention.', '[MASK]'),\n",
    "                               ('0 1 2 3 4 [MASK] 6 7 8.', '[MASK]')\n",
    "                              ]\n",
    "    custom_contexts = []\n",
    "    # custom_contexts_acts = {layer: [] for layer in layers}\n",
    "    custom_dists = {layer: [] for layer in layers}\n",
    "    for custom_txt, tok in custom_contexts_untokenized:\n",
    "        custom_doc, custom_doc_acts = bert.get_toks_and_acts(custom_txt)\n",
    "        custom_pos = custom_doc.index(tok)\n",
    "        custom_contexts.append((custom_doc, custom_pos))\n",
    "        for layer in layers:\n",
    "            _act = doc_acts[layer][tok_of_interest_idx]\n",
    "            _custom_act = custom_doc_acts[layer][custom_pos]\n",
    "            if spherize: \n",
    "                _act = acts_util.spherize([_act])[0]\n",
    "                _custom_act = acts_util.spherize([_custom_act])[0]\n",
    "            dist = np.linalg.norm(_custom_act - _act)\n",
    "            custom_dists[layer].append(dist)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# VISUALIZE\n",
    "\n",
    "override_params = True  # useful for quick iteration on visualization\n",
    "if override_params:\n",
    "    vis_color = True\n",
    "    vis_size = True\n",
    "    vis_masked_KNNs = True\n",
    "    vis_corpus_KNNs = True\n",
    "    vis_custom_contexts = True\n",
    "    together = True\n",
    "    pruning=True  \n",
    "    save_to_html = False\n",
    "    # if pruning is true, in the masked neighbors vis, first the closest 0-length mask is presented, \n",
    "    # then jumps to the closes 1-length max, etc - forming a kind of slow pruning to capture the essence of the context.\n",
    "# other vis params\n",
    "max_font_size = 10\n",
    "n_neighbors_to_vis = 50\n",
    "token_styler = lambda t: t\n",
    "token_styler = lambda t: style(font_size(fix_size(t),7), 'line-height:0px;')  # another pretty styling option\n",
    "if save_to_html: complete_html = ''\n",
    "\n",
    "# vis\n",
    "rgbs = {layer:vis_util.channels_to_rgbs(doc_reduced_acts[layer]) for layer in layers}\n",
    "neighborhood_idx = toks_of_interest.index(tok_of_interest_idx)  # it should be one of the toks of interest we searched for\n",
    "tok_of_interest_html = context_html(doc, toks_of_interest[tok_of_interest_idx])\n",
    "display(HTML(tok_of_interest_html))\n",
    "if save_to_html: complete_html += tok_of_interest_html + '<br>'\n",
    "print()\n",
    "\n",
    "# vis legend\n",
    "if vis_color:\n",
    "    pure_rgbs = vis_util.channels_to_rgbs(np.eye(dim))\n",
    "    html = ''\n",
    "    for i, rgb in enumerate(pure_rgbs):\n",
    "        html += html_util.style(f' {i} ', css=f'background-color: {html_util.rgb_to_color(*rgb)}')\n",
    "    print('Legend')\n",
    "    display(HTML(html))\n",
    "    if save_to_html: complete_html += html + '<br>'\n",
    "    print() \n",
    "        \n",
    "bluer = highlighter('lightblue')\n",
    "greener = highlighter('limegreen')\n",
    "greyer = highlighter('grey')\n",
    "masker = highlighter('black')\n",
    "layers_neighs = []\n",
    "for layer_idx, layer in list(enumerate(layers))[:]:\n",
    "    display(HTML(f'{layer}'))\n",
    "    if save_to_html: complete_html += f'{layer}' + '<br>'\n",
    "    # vis sample\n",
    "    _rgbs = rgbs[layer]\n",
    "    if vis_size:\n",
    "        _sizes = doc_acts_sizes[layer]\n",
    "        _sizes = (_sizes - np.min(_sizes)) / (np.max(_sizes) - np.min(_sizes))    \n",
    "    if vis_color:\n",
    "        color_html = ''\n",
    "        for pos, tok in enumerate(doc):\n",
    "            if vis_size:\n",
    "                css = f'background-color: {html_util.rgb_to_color(*_rgbs[pos])}; font-size: {_sizes[pos]*max_font_size}pt;'\n",
    "            else:\n",
    "                css = f'background-color: {html_util.rgb_to_color(*_rgbs[pos])}; font-size: {max_font_size}pt;'\n",
    "            color_html += html_util.style(f' {tok} ', css=css)\n",
    "        display(HTML(tok_of_interest_html))\n",
    "        if save_to_html: complete_html += tok_of_interest_html + '<br>'\n",
    "        display(HTML(color_html))\n",
    "        if save_to_html: complete_html += color_html + '<br>'\n",
    "    \n",
    "    # vis knns\n",
    "    layer_neighbors = []\n",
    "    if together:\n",
    "        neighbors = []\n",
    "        if vis_masked_KNNs:\n",
    "            neighbors.extend([(context, dist, 'masked') for context, dist in masked_neighborhoods[layer][neighborhood_idx]][1:])\n",
    "        if vis_corpus_KNNs:\n",
    "            neighbors.extend([(context, dist, 'corpus') for context_id, context, dist in corpus_neighborhoods[layer][neighborhood_idx]][1:])\n",
    "        if vis_custom_contexts:\n",
    "            neighbors.extend([(context, dist, 'custom') for context, dist in zip(custom_contexts, custom_dists[layer])])\n",
    "        neighbors.sort(key=lambda t: t[1])\n",
    "        for neigh_context, neigh_dist, neigh_dataset in neighbors[:n_neighbors_to_vis]:\n",
    "            html = f'({neigh_dist:.3f}) '\n",
    "            marker = bluer if not any([neigh_context in neighs for neighs in layers_neighs]) else greyer\n",
    "            if neigh_dataset == 'masked':\n",
    "                html += context_html(*neigh_context, masker=masker, token_styler=token_styler)\n",
    "            elif neigh_dataset == 'corpus':\n",
    "                html += context_html(*neigh_context, marker=marker, masker=masker, token_styler=token_styler)\n",
    "            elif neigh_dataset == 'custom':\n",
    "                html += context_html(*neigh_context, marker=greener, masker=masker, token_styler=token_styler)\n",
    "            display(HTML(html))\n",
    "            if save_to_html: complete_html += html + '<br>'\n",
    "            layer_neighbors.append(neigh_context)\n",
    "    else:\n",
    "        if vis_masked_KNNs:\n",
    "            neighbors = masked_neighborhoods[layer][neighborhood_idx]\n",
    "            if pruning:\n",
    "                for mask_len_to_find in range(len(doc)-2):\n",
    "                    for neigh_context, neigh_dist in neighbors:\n",
    "                        neighbors_so_far.append(neigh_context)\n",
    "                        neigh_toks, neigh_pos = neigh_context\n",
    "                        mask_len = len([tok for tok in neigh_toks if tok == '[MASK]'])\n",
    "                        if mask_len == mask_len_to_find:\n",
    "                            html = ''\n",
    "                            html += token_styler(f'({neigh_dist:.3f}) ') +  context_html(*neigh_context, token_styler=token_styler)\n",
    "                            display(HTML(html))\n",
    "                            if save_to_html: complete_html += html + '<br>'\n",
    "                            break\n",
    "            else:\n",
    "                for neigh_context, neigh_dist in neighbors[:n_neighbors_to_vis]:  # masked neighbors\n",
    "                    html = token_styler(f'({neigh_dist:.3f}) ') + context_html(*neigh_context, token_styler=lambda t: token_styler(fix_size(t)))\n",
    "                    display(HTML(html))\n",
    "                    if save_to_html: complete_html += html + '<br>'\n",
    "                    layer_neighbors.append(neigh_context)\n",
    "        if vis_corpus_KNNs:\n",
    "            neighbors = corpus_neighborhoods[layer][tok_of_interest_idx][:n_neighbors_to_vis]\n",
    "            for neigh_id, neigh_context, neigh_dist in neighbors:  # corpus neighbors\n",
    "                marker = bluer if not any([neigh_context in neighs for neighs in layers_neighs]) else greyer\n",
    "                html = token_styler(f'{neigh_dist:.3f}') + context_html(*neigh_context, marker=marker, token_styler=token_styler)\n",
    "                display(HTML(html))\n",
    "                if save_to_html: complete_html += html + '<br>'\n",
    "                layer_neighbors.append(neigh_context)\n",
    "        if vis_custom_contexts:\n",
    "            for context, dist in zip(custom_contexts, custom_dists[layer]):\n",
    "                marker = greener\n",
    "                html = token_styler(f'{dist:.3f}') + context_html(*context, marker=marker, token_styler=token_styler)\n",
    "                display(HTML(html))\n",
    "                if save_to_html: complete_html += html + '<br>'\n",
    "                layer_neighbors.append(context)\n",
    "    layers_neighs.append(layer_neighbors)\n",
    "    print('.')\n",
    "    print('.')\n",
    "    print('.')\n",
    "\n",
    "if save_to_html: open('../../../building-blocks.html', 'w').write(complete_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Visualize the evolution of context and all neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import umap\n",
    "# import itertools\n",
    "# # VIS\n",
    "# from bokeh.plotting import figure, show, output_file\n",
    "# from IPython.core.display import display, HTML\n",
    "# from bokeh.io import output_notebook\n",
    "# from bokeh.models import Div, HoverTool, ColumnDataSource, PanTool, BoxZoomTool, WheelZoomTool, ResetTool\n",
    "# from bokeh.layouts import gridplot\n",
    "# from bokeh.palettes import Category20\n",
    "# view_vis_as_html = False\n",
    "# output_notebook()\n",
    "# if view_vis_as_html:\n",
    "#     output_file('visualize-wiki.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.express as px\n",
    "# import plotly.io as pio\n",
    "# pio.renderers.default = 'iframe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fresh visualization\n",
    "# grid = vis_util.Grid()\n",
    "# verbose = True\n",
    "# palette = Category20[20]\n",
    "# layer_palette = {layer: palette[layer_idx] for layer_idx, layer in enumerate(layers)}\n",
    "# n_neighbors = 20  # todo: set automatically from corpus knns section\n",
    "\n",
    "# col = []\n",
    "# points_ids = []\n",
    "# points_contexts = []\n",
    "# points_layers = []\n",
    "# points_colors = []\n",
    "# points_htmls = []\n",
    "# for layer in layers:\n",
    "#     _points_ids, _points_contexts, _ = zip(*corpus_neighborhoods[layer][tok_of_interest_idx])\n",
    "#     points_ids += _points_ids\n",
    "#     points_contexts += _points_contexts \n",
    "#     points_layers += [layer] * len(_points_ids)\n",
    "#     points_colors += [layer_palette[layer]] * len(_points_ids)\n",
    "#     points_htmls += [context_util.context_html(*context) for context in _points_contexts]\n",
    "# reducer = umap.UMAP(random_state=1)\n",
    "# for layer_to_plot in layers:\n",
    "#     if verbose: print('Gathering plot info...')\n",
    "#     points_acts = corpus_acts[layer_to_plot][points_ids]\n",
    "#     points_2d = reducer.fit_transform(points_acts)\n",
    "#     tok_point_act = doc_acts[layer_to_plot][tok_of_interest_idx]\n",
    "#     tok_point_2d = reducer.transform([tok_point_act])[0]\n",
    "#     if verbose: print('Making empty plot...')\n",
    "#     p: figure = vis_util.empty_plot(size=200)\n",
    "#     if verbose: print('Adding points....')\n",
    "#     source = ColumnDataSource({'x': points_2d[:,0], 'y': points_2d[:,1], 'color': points_colors, 'label': points_htmls})\n",
    "#     p.circle('x', 'y', color='color', source=source)\n",
    "#     star_source = ColumnDataSource({'x': [tok_point_2d[0],], 'y': [tok_point_2d[1],], 'color': [layer_palette[layer_to_plot],], 'size': [10], 'label': [tok_of_interest_html,]})\n",
    "#     p.star('x', 'y', color='color', siz='size', source=star_source)\n",
    "#     if verbose: print('Adding tools...')\n",
    "#     p.tools = [WheelZoomTool(), PanTool(), BoxZoomTool(), ResetTool(), vis_util.hover_tool('label')]\n",
    "#     col.append(p)\n",
    "# grid.add_column('', col)\n",
    "# grid.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #     colors = ['red' if neigh_layer==layer else 'black' for neigh_layer in all_neighs_layers]\n",
    "#     colors = []\n",
    "#     for neigh_layer, neigh_context in zip(all_neighs_layers, all_neighs_contexts):\n",
    "#         color = 'black'\n",
    "#         if neigh_layer == layer:\n",
    "#             color = 'blue'\n",
    "#         if neigh_context in neighs_contexts_so_far:\n",
    "#             print(layer, neighs_contexts_so_far)\n",
    "#             color = 'green'\n",
    "#         colors.append(color)\n",
    "#         neighs_contexts_so_far.append(neigh_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Try a custom sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose\n",
    "new_text = 'Later that day, [MASK].'\n",
    "new_text_tok_of_interest = '[MASK]'\n",
    "\n",
    "# vis\n",
    "for layer in layers:\n",
    "    new_doc, new_acts = bert.get_toks_and_acts(new_text)\n",
    "    new_pos = new_doc.index(new_text_tok_of_interest)\n",
    "    current_act = doc_acts[layer][tok_of_interest_idx]\n",
    "    if spherize: current_act = acts_util.spherize([current_act])[0]\n",
    "    new_act = new_acts[layer][new_pos]\n",
    "    if spherize: new_act = acts_util.spherize([new_act])[0]\n",
    "    display(HTML(f'Layer {layer}'))\n",
    "    dist = np.linalg.norm(current_act - new_act)\n",
    "    token_styler = lambda t: font_size(t,max_font_size)\n",
    "    html = token_styler(f'{dist:.3f}'[:])\n",
    "    html += context_html(new_doc, new_pos, marker=bluer, token_styler=token_styler)\n",
    "    display(HTML(html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
